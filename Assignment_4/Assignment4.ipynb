{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d08b1ae-24ed-47cc-84af-56684de13b23",
   "metadata": {},
   "source": [
    "# SNLP Assignment 4\n",
    "\n",
    "Name 1: Entang Wang<br/>\n",
    "Student id 1: 7069521<br/>\n",
    "Email 1: enwa00001@stud.uni-saarland.de<br/>\n",
    "\n",
    "\n",
    "Name 2: <br/>\n",
    "Student id 2: <br/>\n",
    "Email 2: <br/> \n",
    "\n",
    "Name 3: <br/>\n",
    "Student id 3: <br/>\n",
    "Email 3: <br/> \n",
    "\n",
    "**Instructions:** Read each question carefully. <br/>\n",
    "Make sure you appropriately comment your code wherever required. Your final submission should contain the completed Notebook. There is no need to submit the data files. <br/>\n",
    "Upload the zipped folder on CMS. Please follow the naming convention of **Name1_studentID1_Name2_studentID2_Name3_studentID3.zip**. Make sure to click on \"Turn-in\" (or the equivalent on CMS) after you upload your submission, otherwise the assignment will not be considered as submitted. Only one member of the group should make the submisssion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6baf84f-c1f1-4d86-80ed-d127e734d96e",
   "metadata": {},
   "source": [
    "# OOVs ( 4 Points)\n",
    "\n",
    "Out-of-vocabulary words are a problem in language modeling, because of data sparsity.\n",
    "In this exercise we will axamine the impact of vocab size on OOV rate and how this affects the performance of the model.\n",
    "\n",
    "1. What are out-of-vocabulary words (OOVs)? (0.25 points)\n",
    "2. What happened to perplexity with low-frequency words? (0.25 points)\n",
    "\n",
    "### Answers:\n",
    "\n",
    "Your answer to 1. and 2. go here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27561edb-a232-4815-8d5d-fbb48e2f54cd",
   "metadata": {},
   "source": [
    "3. Load and split the data into a train and test set (70:30 ratio). Do not randomize leave the order as is. (0.5point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b6bb2-570f-45f4-a4c1-ac359964790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')\n",
    "\n",
    "### TODO\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    ''' Function that loads the treebank corpus from nltk and preprocesses it'''\n",
    "    raise NotImplementedError\n",
    "\n",
    "def train_test_split(corpus, train_ratio=0.7):\n",
    "    '''Splits the corpus using a 70:30 ratio. Do not randomize anything here. use the original order\n",
    "    Input: corpus - preprocessed test\n",
    "    Output: tuple of train and test set'''\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e12e31-24dc-4046-a1b9-b2964e6c2527",
   "metadata": {},
   "source": [
    "4. Complete the function that selects the top n frequent words to form a vocabulary. (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de5d69-5212-47c5-a851-03895bd020a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_vocab(tokens, top_n: int) -> set:\n",
    "    '''Make the top_n frequent vocabulary from a corpus\n",
    "    Input:tokens - list of tokens\n",
    "         top_n  - int\n",
    "    Output: the vocabulary - set of words'''\n",
    "    raise NotImplementedError\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58700f6a-3068-4613-bc16-dcf280a70f34",
   "metadata": {},
   "source": [
    "5. Complete the function that restricts a corpus to the top_n Vocabulary, i.e. replace  all OOVs with a new `<unk>` token. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87784b35-e436-49d7-bd8b-93c2dd2dff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def restrict_vocab(corpus, vocab):\n",
    "    '''Make the corpus fit inside the vocabulary using <unk>\n",
    "    Input: corpus - text to be resticted\n",
    "         vocab  - set of words\n",
    "    Output: Corpus resticted to vocab'''\n",
    "    raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da51e38-aea2-4c94-ba4d-bcf47811c6c7",
   "metadata": {},
   "source": [
    "6. Plot the OOV rate of the test set for varying vocabulary sizes. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50378ee-ba14-46c1-b98c-cf5d2c218e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OOV_rate(text, vocab):\n",
    "    ''' Function that returns the OOV rate for a given corpus and Vocab\n",
    "    Input: corpus - preprocessed text\n",
    "         vocab  - set of words\n",
    "    Output: OOV rate - float '''\n",
    "    raise NotImplementedError\n",
    "\n",
    "def plot_OOV_rates(corpus, vocab, top_n):\n",
    "     ''' Function that returns the OOV rate for a given corpus and Vocab\n",
    "    Input: corpus - preprocessed text\n",
    "         vocab  - set of words\n",
    "         top_n - list[int] '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2486f7-848e-4f0e-8c54-31ce8a94cbf0",
   "metadata": {},
   "source": [
    "7. Why would we restrict Vocabulary size if OOVs are a problem.(0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72ee414-3971-4e5b-a8c6-900b456d60ce",
   "metadata": {},
   "source": [
    "# Tokenization (6 Points)\n",
    "\n",
    "In the previous part we replaced OOVs with a`<unk>` Token. Another approach is to change tokenization to split words in to subwords. In the lecture we learnt about two methods that do this BPE and Morfessor. In this part we will see how they work using text data in English and Hindi. We will also compare them by looking at the entropy of the token distributions and how they handle OOVs.\n",
    "\n",
    "1. Load the parallel corpus (English-Hindi), preprocess and split the text in words for both languages. Also split into train and test sets using the same ratio as in the previous part.(1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123c66ce-33e1-4177-bffc-2bb847e97bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': 0, 'src': \"However, Paes, who was partnering Australia's Paul Hanley, could only go as far as the quarterfinals where they lost to Bhupathi and Knowles\", 'tgt': 'आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Samanantar dataset for English-Hindi\n",
    "dataset = load_dataset(\"ai4bharat/samanantar\", \"hi\", split=\"train\",streaming = True)\n",
    "\n",
    "# Access the  first 1000 samples of the train split\n",
    "data = []\n",
    "for i, sample in enumerate(dataset):\n",
    "    if i == 1000:\n",
    "        break\n",
    "    data.append(sample)\n",
    "\n",
    "# Print a sample\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44cbafe-384c-475d-b16f-272b681497ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584685af-bfce-4f3e-b931-ddcb0f01ec96",
   "metadata": {},
   "source": [
    "2. Train a BPE tokenizer for both languages. (1 point)\n",
    "3. Compute the entropy and OOV rate of the test set for both languages. What does the entropy tell us? (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc925d4-21b8-4190-b616-79a9419d0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "vocab_size = 500\n",
    "\n",
    "#Train BPE model\n",
    "\n",
    "\n",
    "#Compute entropys and OOV rates\n",
    "\n",
    "\n",
    "print(f\"BPE entropy english: {bpe_entropy_en:.2f}\")\n",
    "print(f\"BPE entropy hindi: {bpe_entropy_hi:.2f}\")\n",
    "print(f\"BPE OOV rate english: {bpe_OOV_rate_en:.2f}\")\n",
    "print(f\"BPE OOV rate hindi_ {bpe_OOV_rate_hi:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef4bfa-b487-491b-a0ce-642d472f5456",
   "metadata": {},
   "source": [
    "4. Train the Morfessor tokenizer on each corpus. Morphesor expects the count followed by the word as a training file.(1 points)\n",
    "\n",
    "   ```\n",
    "        22 the\n",
    "        1 hello\n",
    "        4 is\n",
    "        1 test-based\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb739e-d3aa-4582-9c4c-fe4a2f49f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import morfessor\n",
    "# save the words with their counts to morfessor_training_en.txt and morfessor_training_hi.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c32f51-124f-4be3-801d-9e6405f374b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the models\n",
    "alpha =  0.53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eaeb88-7cea-4979-a5be-9f1cd36b16e4",
   "metadata": {},
   "source": [
    "5. Tokenize each test set again using Morfessor. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32936a-ad02-48b5-9dd7-63dc44a61b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize test sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e006c99-7700-4286-b07a-517ac07b87b5",
   "metadata": {},
   "source": [
    "6. Compare the OOV rate and entropy to BPE. How do they compare for both languages? (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17081332-1bd6-4577-adc7-96567082147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute entropys and OOV rates\n",
    "\n",
    "print(f\"Morfessor entropy english: {morfessor_entropy_en:.2f}\")\n",
    "print(f\"Morrfessor entropy hindi: {morfessor_entropy_hi:.2f}\")\n",
    "print(f\"Morfessor OOV rate english: {morfessor_OOV_rate_en:.2f}\")\n",
    "print(f\"Morfessor OOV rate hindi: {morfessor_OOV_rate_hi:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
