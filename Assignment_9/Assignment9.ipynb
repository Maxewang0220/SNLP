{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b39307",
   "metadata": {},
   "source": [
    "# SNLP Assignment 9\n",
    "\n",
    "Name 1: <br/>\n",
    "Student id 1: <br/>\n",
    "Email 1: <br/>\n",
    "\n",
    "\n",
    "Name 2: <br/>\n",
    "Student id 2: <br/>\n",
    "Email 2: <br/> \n",
    "\n",
    "Name 3: <br/>\n",
    "Student id 3: <br/>\n",
    "Email 3: <br/> \n",
    "\n",
    "**Instructions:** Read each question carefully. <br/>\n",
    "Make sure you appropriately comment your code wherever required. Your final submission should contain the completed Notebook. There is no need to submit the data files. <br/>\n",
    "Upload the zipped folder on CMS. Please follow the naming convention of **Name1_studentID1_Name2_studentID2_Name3_studentID3.zip**. Make sure to click on \"Turn-in\" (or the equivalent on CMS) after you upload your submission, otherwise the assignment will not be considered as submitted. Only one member of the group should make the submisssion.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## !pip install -q transformers datasets sklearn-crfsuite seqeval  use it if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a49d7f",
   "metadata": {},
   "source": [
    "## Ex 9.3: Transformers and CRFs  \n",
    "\n",
    "In this exercise, you will enhance a Transformer-based Named Entity Recognition (NER) model by adding a Conditional Random Field (CRF) layer on top of it. The goal is to compare a baseline Transformer model with a hybrid Transformer+CRF model on a subset of the CoNLL-2003 dataset, which you will load using Hugging Face datasets.\n",
    "\n",
    "The baseline model uses a Transformer’s built-in token classification head, while the hybrid model extracts embeddings from the Transformer and feeds them into a separate CRF model for prediction.\n",
    "\n",
    "The dataset loading and model initialization code is already provided.                  [**Total**: 5 points]\n",
    "\n",
    "Your task is to complete the following functions:\n",
    "\n",
    "- `get_transformer_predictions()`: Make NER predictions using a Transformer’s classification head. (0.5 points)\n",
    "\n",
    "- `get_transformer_embeddings()`: Extract token embeddings from a pre-trained Transformer. (0.5 points)\n",
    "\n",
    "- `embeddings_to_features()`: Convert token embeddings into CRF-compatible feature dictionaries. (0.5 points)\n",
    "\n",
    "- `train_crf_model()`: Train a CRF using sklearn-crfsuite. (0.5 points)\n",
    "\n",
    "- `evaluate_predictions()`: Evaluate predictions using F1 score and classification report. (0.5 points)\n",
    "\n",
    "- `plot_per_label_f1()`: Plot the per-label F1 scores as a horizontal bar chart. (0.5 points)\n",
    "\n",
    "- `plot_confusion_matrix()` : Plot the confusion matrix of predicted vs. true tags. (0.5 points)\n",
    "\n",
    "Your goal is to compare the performance of:\n",
    "\n",
    "- A baseline model that uses only the Transformer’s classification head.\n",
    "\n",
    "- A hybrid model that feeds Transformer embeddings into a CRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForTokenClassification\n",
    "import sklearn_crfsuite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e352016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small subset of the dataset\n",
    "def load_conll_subset(train_size=500, test_size=100):\n",
    "    \"\"\"\n",
    "    Load a small subset of the CoNLL-2003 dataset for quick testing.\n",
    "    \"\"\"\n",
    "    train = load_dataset('conll2003', split='train', trust_remote_code=True).select(range(train_size))\n",
    "    test = load_dataset('conll2003', split='validation', trust_remote_code=True).select(range(test_size))\n",
    "    return train, test\n",
    "\n",
    "# Load models and tokenizer\n",
    "def load_models(model_checkpoint=\"distilbert-base-cased\", num_labels=9):\n",
    "    \"\"\"\n",
    "    Load the tokenizer and models for token classification and embeddings.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "    model_cls = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "    model_embed = AutoModel.from_pretrained(model_checkpoint)\n",
    "    return tokenizer, model_cls, model_embed\n",
    "\n",
    "# Get label mapping\n",
    "def get_label_mappings(train_dataset):\n",
    "    \"\"\"\n",
    "    Get label mappings from the training dataset.\n",
    "    \"\"\"\n",
    "    labels = train_dataset.features['ner_tags'].feature.names\n",
    "    id2label = {i: label for i, label in enumerate(labels)}\n",
    "    return labels, id2label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde29d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer_predictions(dataset, tokenizer, model, id2label):\n",
    "    \"\"\"\n",
    "    Generate NER predictions using the classification head of a pretrained Transformer model.\n",
    "\n",
    "    Args:\n",
    "        dataset (datasets.Dataset): A dataset of tokenized sequences with NER tags.\n",
    "        tokenizer (PreTrainedTokenizer): HuggingFace tokenizer corresponding to the model.\n",
    "        model (PreTrainedModel): Transformer model with a token classification head.\n",
    "        id2label (dict): Mapping from tag ID to string label.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A pair (true_labels, predicted_labels), where each is a list of token-level NER label sequences.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_transformer_embeddings(dataset, tokenizer, model, id2label):\n",
    "    \"\"\"\n",
    "    Extract last-layer hidden state embeddings from a Transformer model and align them to original tokens.\n",
    "\n",
    "    Args:\n",
    "        dataset (datasets.Dataset): A dataset of tokenized sequences with NER tags.\n",
    "        tokenizer (PreTrainedTokenizer): HuggingFace tokenizer corresponding to the model.\n",
    "        model (PreTrainedModel): Transformer model (without classification head) that outputs hidden states.\n",
    "        id2label (dict): Mapping from tag ID to string label.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A pair (all_embeddings, all_labels), where:\n",
    "            - all_embeddings is a list of lists of token-level embedding vectors (np.ndarray).\n",
    "            - all_labels is a list of NER label sequences corresponding to each sentence.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def embeddings_to_features(sentence_embeddings):\n",
    "    \"\"\"\n",
    "    Plot a confusion matrix for NER predictions.\n",
    "\n",
    "    Args:\n",
    "        true (List[List[str]]): Ground truth token label sequences.\n",
    "        pred (List[List[str]]): Predicted token label sequences.\n",
    "        labels (List[str]): List of all possible labels in a consistent order.\n",
    "        title (str): Title to prefix the plot with (typically the model name).\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def train_crf_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a linear-chain CRF using token-level feature dictionaries.\n",
    "\n",
    "    Args:\n",
    "        X_train (List[List[dict]]): List of token-level feature sequences (sentences).\n",
    "        y_train (List[List[str]]): List of corresponding label sequences.\n",
    "\n",
    "    Returns:\n",
    "        sklearn_crfsuite.CRF: A trained CRF model.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def evaluate_predictions(true, pred, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Compute and print the F1 score for sequence labeling predictions.\n",
    "\n",
    "    Args:\n",
    "        true (List[List[str]]): Ground truth token label sequences.\n",
    "        pred (List[List[str]]): Predicted token label sequences.\n",
    "        model_name (str): Name of the model for display purposes.\n",
    "\n",
    "    Returns:\n",
    "        float: The micro-averaged F1 score.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_per_label_f1(true, pred, title=\"Model\"):\n",
    "    \"\"\"\n",
    "    Plot a horizontal bar chart of per-label F1 scores.\n",
    "\n",
    "    Args:\n",
    "        true (List[List[str]]): Ground truth token label sequences.\n",
    "        pred (List[List[str]]): Predicted token label sequences.\n",
    "        title (str): Title to prefix the plot with (typically the model name).\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(true, pred, labels, title=\"Model\"):\n",
    "    \"\"\"\n",
    "    Plot a confusion matrix for NER predictions.\n",
    "\n",
    "    Args:\n",
    "        true (List[List[str]]): Ground truth token label sequences.\n",
    "        pred (List[List[str]]): Predicted token label sequences.\n",
    "        labels (List[str]): List of all possible labels in a consistent order.\n",
    "        title (str): Title to prefix the plot with (typically the model name).\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a424a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data and models...\")\n",
    "train_data, test_data = load_conll_subset()\n",
    "tokenizer, model_cls, model_embed = load_models()\n",
    "labels, id2label = get_label_mappings(train_data)\n",
    "\n",
    "print(\"\\n--- Running Baseline (Transformer-Only) Experiment ---\")\n",
    "baseline_true, baseline_pred = get_transformer_predictions(test_data, tokenizer, model_cls, id2label)\n",
    "baseline_f1 = evaluate_predictions(baseline_true, baseline_pred, model_name=\"Transformer Only\")\n",
    "\n",
    "print(\"\\n--- Running Transformer + CRF Experiment ---\")\n",
    "train_embs, y_train = get_transformer_embeddings(train_data, tokenizer, model_embed, id2label)\n",
    "test_embs, y_test = get_transformer_embeddings(test_data, tokenizer, model_embed, id2label)\n",
    "\n",
    "X_train = [embeddings_to_features(e) for e in train_embs]\n",
    "X_test = [embeddings_to_features(e) for e in test_embs]\n",
    "\n",
    "crf_model = train_crf_model(X_train, y_train)\n",
    "y_pred_crf = crf_model.predict(X_test)\n",
    "\n",
    "crf_f1 = evaluate_predictions(y_test, y_pred_crf, model_name=\"Transformer + CRF\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Transformer Only F1 Score:     {baseline_f1:.4f}\")\n",
    "print(f\"Transformer + CRF F1 Score:    {crf_f1:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c35353",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrices\")\n",
    "plot_confusion_matrix(baseline_true, baseline_pred,labels=labels, title=\"Transformer only\")\n",
    "plot_confusion_matrix(y_test, y_pred_crf, labels=labels, title=\"Transformer + CRF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e2c8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Per label F1-scrore\")\n",
    "plot_per_label_f1(baseline_true, baseline_pred, title=\"Transformer only\")\n",
    "plot_per_label_f1(y_test, y_pred_crf, title=\"Transformer + CRF\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c1504",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "\n",
    "1. Explain your results. Why do you think a CRF might be more effective than a simple classification head in certain NER tasks? **(0.25 points)**\n",
    "\n",
    "2. Under what circumstances might the CRF layer not improve performance over the baseline Transformer model?  **(0.25 points)**\n",
    "\n",
    "3. In what way does a CRF impose **global sequence-level constraints**, and how does this affect prediction quality?  **(0.25 points)**\n",
    "\n",
    "4. What properties of Transformer embeddings make them well-suited (or not) for CRF-based modeling, as compared to LSTMs, for example? **(0.25 points)**\n",
    "\n",
    "5. Do you think you could use this pipeline for domain adaptation (e.g., transferring NER from news articles to scientific literature)?  **(0.25 points)**\n",
    "\n",
    "6. Why do you think we are using F1-score as a metric here? **(0.25 points)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
